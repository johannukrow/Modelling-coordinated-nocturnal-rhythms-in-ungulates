{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.integrate import quad\n",
    "from scipy.special import beta as Beta\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import warnings\n",
    "import scipy.optimize as optimize\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import trange\n",
    "from collections import namedtuple\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "\n",
    "Params = namedtuple('Parameters', ['mu', 'sigma', 'alpha', 'beta', 'p'])\n",
    "str2float = lambda x: [float(k) for k in x[1:-1].split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Parameter estimation for individuals within the (I)BN is based on the raw standing cycles (SC) and lying fractions (LF) distributions, while estimation of $u$ and $\\delta$ for pairs of processes is based on the CCF shape, which is compared to a CCF predicted under the assumption of $u=1$ and $ \\delta=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Functions in the IBN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the SC density function in the IBN model. The density is given as\n",
    "$$f_{SC}(c) = \\frac{1-\\pi}{1+\\pi} f_C(c) + \\frac{2\\pi}{(1+\\pi)B(\\beta, \\alpha)}\\cdot\\int_c^\\infty  \\frac{f_C(y)}{y^2} \\left[ t \\int_{\\frac{c}{y}}^1  \\xi(\\alpha,\\beta,x) dx + (y-t) \\int_{1-\\frac{c}{y}}^1  \\xi(\\alpha,\\beta,x) dx \\right] dy,$$\n",
    "where $f_C$ is the PDF of $\\mathcal{N}_+(\\mu,\\sigma)$, $B$ is the beta function and\n",
    "$\\xi(\\alpha,\\beta,x):= x^{\\beta-3}(1-x)^{\\alpha-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_SC(c: float, mu: float, sigma: float, alpha: float, beta: float, pi: float) -> float:\n",
    "    \"\"\" Density function of standing cycles (SC) in the IBN model. \"\"\"\n",
    "    if c < 0:\n",
    "        return 0\n",
    "    \n",
    "    f_C = lambda c: stats.truncnorm.pdf(c, -mu/sigma, np.inf, loc=mu, scale=sigma)\n",
    "\n",
    "    # BN:\n",
    "    if not pi:\n",
    "        return f_C(c)\n",
    "    \n",
    "    # IBN:\n",
    "    xi = lambda x: x**(beta - 3) * (1 - x)**(alpha - 1)\n",
    "\n",
    "    summand1 = (1 - pi) / (1 + pi) * f_C(c)\n",
    "\n",
    "    factor2 = 2 * pi / ((1 + pi) * Beta(beta, alpha))\n",
    "\n",
    "    I = lambda v: quad(xi, v, 1)[0]\n",
    "    summand2 = factor2 * quad(lambda y: f_C(y) / y**2 * (c* I(c/y) + (y - c) * I(1 - c/y)), c, np.inf)[0]  # Lemma 5.1\n",
    "\n",
    "    return summand1 + summand2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the LF density function in the IBN model. The density is given as\n",
    "$$f_{LF}(c) = \\frac{1-\\pi}{1+\\pi} f_F(c) + \\frac{\\pi}{1+\\pi} + \\frac{2\\pi}{(1+\\pi)c^2\\cdot B(\\beta, \\alpha)} \\int_{c^{-1}-1}^\\infty x^{\\beta -3} (1 + x)^{-\\beta-\\alpha} \\cdot (x-c^{-1}+1)dx$$\n",
    "for $c\\in[0,1]$ and $f_{LF}(c)=0$ for $c\\notin[0,1]$, where $f_F$ is the PDF of $Beta(\\alpha,\\beta)$ and $B$ is the beta function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_LF(c: float, alpha: float, beta: float, pi: float) -> float:\n",
    "    \"\"\" Density function of lying fractions (LF) in the IBN model. \"\"\"\n",
    "    if c < 0 or c > 1:\n",
    "        return 0\n",
    "    \n",
    "    f_F = lambda x: stats.beta.pdf(x, alpha, beta)\n",
    "\n",
    "    # BN:\n",
    "    if not pi:\n",
    "        return f_F(c)\n",
    "    \n",
    "    # IBN:\n",
    "    z = 1/c - 1\n",
    "    summand1 = (1 - pi) / (1 + pi) * f_F(c)\n",
    "\n",
    "    summand2 = pi / (1 + pi)\n",
    "\n",
    "    factor3 = 2 * pi / ((1 + pi) * c**2)\n",
    "\n",
    "    I = lambda x: stats.betaprime.pdf(x, beta, alpha) * (1 - z/x) / x\n",
    "\n",
    "    summand3 = factor3 * quad(I, z, np.inf)[0]\n",
    "\n",
    "    return summand1 + summand2 + summand3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, start values for $\\alpha$ and $\\beta$ in the optimization algorithm inside the following parameter estimation functions are based on Method of Moments estimators for the Beta distribution, given by\n",
    "\n",
    "$$\n",
    "\\hat{\\alpha} = \\bar{X} \\left( \\frac{\\bar{X}(1 - \\bar{X})}{s^2} - 1 \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (1 - \\bar{X}) \\left( \\frac{\\bar{X}(1 - \\bar{X})}{s^2} - 1 \\right)\n",
    "$$\n",
    "\n",
    "where $\\bar{X}$ is the sample mean and $s^2$ is the sample variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_mom = lambda l: np.mean(l) * (np.mean(l) * (1 - np.mean(l)) / np.var(l) - 1)\n",
    "beta_mom = lambda l: (1 - np.mean(l)) * (np.mean(l) * (1 - np.mean(l)) / np.var(l) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting function in the (I)BN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the theoretical PDFs of SCs, $f_{SC}$ and LFs, $f_{LF}$ to their empirically observed histograms.\n",
    "\n",
    "We use $K=20$ equally sized bins for the histogram of SC lengths. Additional simulation studies showed no notable improvement in model fit or parameter estimation with higher bin counts, indicating that 20 bins provide an effective balance between resolution and computational efficiency. These have a bin size of $\\Delta^{(j)}_{SC} := {(\\max_i c^{(j)}_i - \\min_i c^{(j)})}/{K}$, where $c^{(j)}_1,\\ldots,c^{(j)}_{n_j}$ denote the lengths of all fully observed SCs in animal $j$. For the histogram of LFs, we proceed analogously, i.e., $\\Delta^{(j)}_{LF}:= {(\\max_i f^{(j)}_i - \\min_i f^{(j)})}/{K}$, where $f^{(j)}_1,\\ldots,f^{(j)}_{n_j}$ denote the LFs of all fully observed SCs in animal $j$. This yields bin-midpoints $b^{SC,(j)}_{k}$ and $b^{LF}_{k}$, $k=1,\\ldots,K,$ as\n",
    "$$b^{SC,(j)}_k := \\min_i c^{(j)}_i + (k - 0.5) \\cdot \\Delta^{(j)}_{SC} \\quad \\text{ and } \\quad b^{LF,(j)}_k := \\min_i f^{(j)}_i + (k - 0.5) \\cdot \\Delta^{(j)}_{LF}.$$\n",
    "The corresponding bin counts, normed to a unit area of the histogram, are then\n",
    "$d^{SC,(j)}_k := (|\\{i: b^{SC,(j)}_k - \\Delta^{(j)}_{SC} \\leq c_i < b^{SC}_k\\}| + \\delta_K(k))/(n_j\\Delta^{(j)}_{SC})$, where \"$<$\" is replaced by \"$\\leq$\" for $k=K$, and analogously for $d^{LF,(j)}_{k}$.\n",
    "\n",
    "\n",
    "Then $f_{SC}$ and $f_{LF}$ are fitted jointly using a non-linear-least squares approach, i.e. parameters are estimated by minimizing the term\n",
    "$$T_j:=\\sum_{k=1}^{K} \\left(\\Delta^{(j)}_{SC}\\right)^{2} \\cdot\\left(f_{SC}(b^{SC}_k) - d^{SC}_k\\right)^2 + \\Delta^2_{LF} \\cdot \\left(f_{LF}(b^{LF}_k) - d^{LF}_k\\right)^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_j$ is minimzed using non-linear-least-squares approach based on the Trust Region Reflective algorithm for minimization. An initial guess for the parameters is given by\n",
    "$$\\mu_0 = \\bar c + 30, \\sigma_0 = sd(f), \\alpha_0=\\hat\\alpha_{MOM},\\text{ and } \\beta=\\hat\\beta_{MOM}.$$\n",
    "Lower and upper bounds on parameters are given by $(0, 660)$ for $\\mu, \\sigma$ and $(0, 1000)$ for $\\alpha, \\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_BN(alpha_mom, beta_mom,\n",
    "\t\t\tx_scs, y_scs, factor_scs,\n",
    "\t\t\tx_lfs, y_lfs, factor_lfs):\n",
    "\t\n",
    "\teps = np.finfo(np.float32).eps\n",
    "\t\n",
    "\t# Combine the x and y values for standing cycles (SCs) and lying fractions (LFs)\n",
    "\tx = np.array([b for b in x_scs] + [b for b in x_lfs])\n",
    "\ty = np.array([factor_scs*b for b in y_scs]  + [factor_lfs*b for b in y_lfs])\n",
    "\n",
    "\tdef compute_SC(x, mu, sigma, a, b, factor_scs):\n",
    "\t\t# Compute the density function for standing cycles (SCs)\n",
    "\t\treturn factor_scs * f_SC(x, mu, sigma, a, b, 0)\n",
    "\n",
    "\tdef compute_LF(x, a, b, factor_lfs):\n",
    "\t\t# Compute the density function for lying fractions (LFs)\n",
    "\t\treturn factor_lfs * f_LF(x, a, b, 0)\n",
    "\n",
    "\tdef f(_x, mu, sigma, a, b):\n",
    "\t\t# Combine the density functions for SCs and LFs\n",
    "\t\tsplit_index = len(_x) // 2\n",
    "\t\ty1 = Parallel(n_jobs=-1)(delayed(compute_SC)(x, mu, sigma, a, b, factor_scs) for x in _x[:split_index])\n",
    "\t\ty2 = Parallel(n_jobs=-1)(delayed(compute_LF)(x, a, b, factor_lfs) for x in _x[split_index:])\n",
    "\t\treturn np.concatenate((y1, y2))\n",
    "\n",
    "\twith warnings.catch_warnings(record=True) as w:\n",
    "\t\twarnings.simplefilter(\"always\")\n",
    "\t\tscs = list(x_scs)\n",
    "\t\t# Fit the combined density function to the data using curve fitting\n",
    "\t\tresult = optimize.curve_fit(f, x, y, p0=[np.mean(scs) + 30, np.std(scs), alpha_mom, beta_mom],\n",
    "\t\t\t\t\t\t\t\t\tbounds=(eps, (660, 660, 1_000, 1_000)), diff_step=0.01)[0]\n",
    "\t\tif any(issubclass(w.category, UserWarning) for w in w):\n",
    "\t\t\twarning_occured = True\n",
    "\t\telse:\n",
    "\t\t\twarning_occured = False\n",
    "\t\toptimal_value = np.sum((f(x, *result) - y)**2)\n",
    "\n",
    "\treturn *result, optimal_value, float(warning_occured)  # Return the optimized parameters, optimal value, and warning flag\n",
    "\n",
    "\n",
    "def fit_BN(scs, lfs, bins=40):\n",
    "\t# Compute Method of Moments estimators for alpha and beta\n",
    "\talpha_moms = alpha_mom(lfs)\n",
    "\tbeta_moms = beta_mom(lfs)\n",
    "\n",
    "\t# Compute histograms for SCs and LFs\n",
    "\tb_y, b_x = np.histogram(scs, bins=bins, density=True)\n",
    "\tdx = b_x[1] - b_x[0]\n",
    "\tfactor_scs = dx\n",
    "\tx_scs = b_x[:-1] + dx/2\n",
    "\ty_scs = b_y.copy()\n",
    "\n",
    "\n",
    "\tb_y, b_x = np.histogram(lfs, bins=bins, density=True)\n",
    "\tdx = b_x[1] - b_x[0]\n",
    "\tfactor_lfs = dx\n",
    "\tx_lfs = b_x[:-1] + dx/2\n",
    "\ty_lfs = b_y.copy()\n",
    "\n",
    "\t# Call the internal function to fit the BN model to the data\n",
    "\treturn _fit_BN(alpha_moms, beta_moms, x_scs, y_scs, factor_scs, x_lfs, y_lfs, factor_lfs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IBN case is analogous to the BN case, except for the additional parameter $\\pi$. The minimization is performed twice, once with initial guess $\\pi_0 = 0.25$ (and other parameters as described above) and once with $\\pi_0 = 0.75$. Then, the result with the lowest achieved error is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_IBN(scs, lfs, bins=40):\n",
    "\teps = np.finfo(np.float32).eps\n",
    "\n",
    "\talpha_moms = alpha_mom(lfs)\n",
    "\tbeta_moms = beta_mom(lfs)\n",
    "\n",
    "\tb_y, b_x = np.histogram(scs, bins=bins, density=True)\n",
    "\tdx = b_x[1] - b_x[0]\n",
    "\tfactor_scs = dx\n",
    "\tx_scs = b_x[:-1] + dx/2\n",
    "\ty_scs = b_y.copy()\n",
    "\n",
    "\tb_y, b_x = np.histogram(lfs, bins=bins, density=True)\n",
    "\tdx = b_x[1] - b_x[0]\n",
    "\tfactor_lfs = dx\n",
    "\tx_lfs = b_x[:-1] + dx/2\n",
    "\ty_lfs = b_y.copy()\n",
    "\n",
    "\t\n",
    "\tx = np.array([b for b in x_scs] + [b for b in x_lfs])\n",
    "\ty = np.array([factor_scs*b for b in y_scs]  + [factor_lfs*b for b in y_lfs])\n",
    "\n",
    "\tdef compute_SC(x, mu, sigma, a, b, p, factor_scs):\n",
    "\t\treturn factor_scs * f_SC(x, mu, sigma, a, b, p/100)\n",
    "\n",
    "\tdef compute_LF(x, a, b, p, factor_lfs):\n",
    "\t\treturn factor_lfs * f_LF(x, a, b, p/100)\n",
    "\n",
    "\tdef f(_x, mu, sigma, a, b, p):\n",
    "\t\tsplit_index = len(_x) // 2\n",
    "\t\ty1 = Parallel(n_jobs=-1)(delayed(compute_SC)(x, mu, sigma, a, b, p, factor_scs) for x in _x[:split_index])\n",
    "\t\ty2 = Parallel(n_jobs=-1)(delayed(compute_LF)(x, a, b, p, factor_lfs) for x in _x[split_index:])\n",
    "\t\treturn np.concatenate((y1, y2))\n",
    "\n",
    "\tresults = {}\n",
    "\tfor p0 in [0.25, 0.75]:\n",
    "\t\twith warnings.catch_warnings(record=True) as w:\n",
    "\t\t\twarnings.simplefilter(\"always\")\n",
    "\t\t\tscs = list(x_scs)\n",
    "\t\t\tresult = optimize.curve_fit(f, x, y, p0=[np.mean(scs) + 30, np.std(scs), alpha_moms, beta_moms, p0*100],\n",
    "\t\t\t\t\t\t\t\t\t\tbounds=(eps, (660, 660, 1_000, 1_000, 100)), diff_step=0.01)[0]\n",
    "\t\t\tif any(issubclass(w.category, UserWarning) for w in w):\n",
    "\t\t\t\twarning_occured = True\n",
    "\t\t\telse:\n",
    "\t\t\t\twarning_occured = False\n",
    "\t\t\toptimal_value = np.sum((f(x, *result) - y)**2)\n",
    "\t\t\tresults[p0] = (*result[:4], result[4]/100, optimal_value, float(warning_occured))\n",
    "\n",
    "\toptimal_values = {key: results[key][-2] for key in results}\n",
    "\tbest_fit = min(optimal_values, key=optimal_values.get)\n",
    "\treturn *results[best_fit], best_fit  # 8 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting function in the S-IBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An analogous fitting approach is applied for the S-IBN. We first fit the theoretical PDFs of SCs and LFs to their respective histograms as described above. Second, in order to estimate the parameters $\\delta$ and $u$, we predict the CCF $\\rho^0_Z(h)$ with parameters $\\hat\\mu, \\hat\\sigma, \\hat\\alpha_1, \\hat \\alpha_2, \\hat \\beta_1, \\hat \\beta_2, \\hat \\pi_1,$ and $\\hat \\pi_2$ for an S-IBN with $u=1, \\delta=0$ and then fit the function $u \\cdot \\rho_Z(h+\\delta)$ to the observed CCF using nonlinear least squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_SIBN(scs1, lfs1, scs2, lfs2, bins=20):\n",
    "\t\"\"\" Fit all parameters except for delta and u of the SIBN model to the data (SCs and LFs of both animals). \"\"\"\n",
    "\teps = np.finfo(np.float32).eps\n",
    "\n",
    "\talpha_moms1 = alpha_mom(lfs1)\n",
    "\tbeta_moms1 = beta_mom(lfs1)\n",
    "\talpha_moms2 = alpha_mom(lfs2)\n",
    "\tbeta_moms2 = beta_mom(lfs2)\n",
    "\n",
    "\tb_y, b_x = np.histogram(scs1, bins=bins, density=True)\n",
    "\tdx = b_x[1] - b_x[0]\n",
    "\tfactor_scs1 = dx\n",
    "\tx_scs1 = b_x[:-1] + dx/2\n",
    "\ty_scs1 = b_y.copy()\n",
    "\n",
    "\tb_y, b_x = np.histogram(lfs1, bins=bins, density=True)\n",
    "\tdx = b_x[1] - b_x[0]\n",
    "\tfactor_lfs1 = dx\n",
    "\tx_lfs1 = b_x[:-1] + dx/2\n",
    "\ty_lfs1 = b_y.copy()\n",
    "\n",
    "\tb_y, b_x = np.histogram(scs2, bins=bins, density=True)\n",
    "\tdx = b_x[1] - b_x[0]\n",
    "\tfactor_scs2 = dx\n",
    "\tx_scs2 = b_x[:-1] + dx/2\n",
    "\ty_scs2 = b_y.copy()\n",
    "\n",
    "\tb_y, b_x = np.histogram(lfs2, bins=bins, density=True)\n",
    "\tdx = b_x[1] - b_x[0]\n",
    "\tfactor_lfs2 = dx\n",
    "\tx_lfs2 = b_x[:-1] + dx/2\n",
    "\ty_lfs2 = b_y.copy()\n",
    "\t\n",
    "\tx = np.array([b for b in x_scs1] + [b for b in x_scs2] + [b for b in x_lfs1] + [b for b in x_lfs2])\n",
    "\ty = np.array([factor_scs1*b for b in y_scs1] + [factor_scs2*b for b in y_scs2] + [factor_lfs1*b for b in y_lfs1] + [factor_lfs2*b for b in y_lfs2])\n",
    "\n",
    "\tdef compute_SC(x, mu, sigma, a, b, p, factor_scs):\n",
    "\t\treturn factor_scs * f_SC(x, mu, sigma, a, b, p/100)\n",
    "\n",
    "\tdef compute_LF(x, a, b, p, factor_lfs):\n",
    "\t\treturn factor_lfs * f_LF(x, a, b, p/100)\n",
    "\n",
    "\tdef f(_x, mu, sigma, a1, b1, p1, a2, b2, p2):\n",
    "\t\tsplit_index = len(_x) // 4\n",
    "\t\ty1 = Parallel(n_jobs=-1)(delayed(compute_SC)(x, mu, sigma, a1, b1, p1, factor_scs1) for x in _x[:split_index])\n",
    "\t\ty2 = Parallel(n_jobs=-1)(delayed(compute_SC)(x, mu, sigma, a2, b2, p2, factor_scs2) for x in _x[split_index:2*split_index])\n",
    "\t\ty3 = Parallel(n_jobs=-1)(delayed(compute_LF)(x, a1, b1, p1, factor_lfs1) for x in _x[2*split_index:3*split_index])\n",
    "\t\ty4 = Parallel(n_jobs=-1)(delayed(compute_LF)(x, a2, b2, p2, factor_lfs2) for x in _x[3*split_index:])\n",
    "\t\treturn np.concatenate((y1, y2, y3, y4))\n",
    "\n",
    "\tresults = {}\n",
    "\tfor p0_0, p1_0 in itertools.product([0.25, 0.75], repeat=2):\n",
    "\t\twith warnings.catch_warnings(record=True) as w:\n",
    "\t\t\twarnings.simplefilter(\"always\")\n",
    "\t\t\tscs = list(x_scs1) + list(x_scs2)\n",
    "\t\t\tresult = optimize.curve_fit(f, x, y, p0=[np.mean(scs) + 30, np.std(scs), alpha_moms1, beta_moms1, p0_0*100, alpha_moms2, beta_moms2, p1_0*100],\n",
    "\t\t\t\t\t\t\t\t\t\tbounds=(eps, (660, 660, 1_000, 1_000, 100, 1_000, 1_000, 100)), diff_step=0.01, xtol=1e-1, ftol=1e-1)[0]\n",
    "\t\t\tif any(issubclass(w.category, UserWarning) for w in w):\n",
    "\t\t\t\twarning_occured = True\n",
    "\t\t\telse:\n",
    "\t\t\t\twarning_occured = False\n",
    "\t\t\toptimal_value = np.sum((f(x, *result) - y)**2)\n",
    "\t\t\tresults[(p0_0, p1_0)] = (*result[:4], result[4]/100, *result[5:7], result[7]/100, optimal_value, float(warning_occured))\n",
    "\n",
    "\toptimal_values = {key: results[key][-2] for key in results}\n",
    "\tbest_fit = min(optimal_values, key=optimal_values.get)\n",
    "\treturn *results[best_fit], *best_fit  # 11 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit $\\delta$ and $u$ we need some more utility functions to compute both the empirical and the theoretical CCFs, which are then fitted using least-squares. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funnctions to imitate pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_cycles(binary_list, length=300):\n",
    "\tif not isinstance(binary_list, np.ndarray):\n",
    "\t\tbinary_list = np.array(binary_list)\n",
    "\tnr_removed_phases = 0\n",
    "\twhile True:\n",
    "\t\tindices = np.concatenate(([0], np.where(np.diff(binary_list) != 0)[0] + 1))\n",
    "\t\tlengths = np.diff(np.concatenate(([0], indices, [len(binary_list)])))[1:]\n",
    "\t\tif lengths.min() >= length:\n",
    "\t\t\tbreak\n",
    "\t\tindex = np.where(lengths < length)[0][0]\n",
    "\t\tbinary_list[indices[index]:indices[index]+lengths[index]+1] = 1 - binary_list[indices[index]]\n",
    "\t\tnr_removed_phases += 1\n",
    "\treturn binary_list, nr_removed_phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to simulate shared nights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shared_night(p1, p2, k=100, max_length=11*60*60, remove_length=300, delta=0) -> tuple[list[int]]:\n",
    "\tassert p1.mu == p2.mu and p1.sigma == p2.sigma\n",
    "\tnight1, night2 = [], []\n",
    "\twhile len(night1) <= (max_length + 10*p1.mu)  or len(night2) <= (max_length + 10*p1.mu):\n",
    "\t\tC = stats.truncnorm.rvs(-p1.mu/p1.sigma, np.inf, loc=p1.mu, scale=p1.sigma, size=k)\n",
    "\t\tF1 = iter(stats.beta.rvs(p1.alpha, p1.beta, size=k))\n",
    "\t\tF2 = iter(stats.beta.rvs(p2.alpha, p2.beta, size=k))\n",
    "\t\tU1 = stats.uniform.rvs(size=(k, 2))\n",
    "\t\tU_mins1 = iter(np.min(U1, axis=1))\n",
    "\t\tU_maxs1 = iter(np.max(U1, axis=1))\n",
    "\t\tU2 = stats.uniform.rvs(size=(k, 2))\n",
    "\t\tU_mins2 = iter(np.min(U2, axis=1))\n",
    "\t\tU_maxs2 = iter(np.max(U2, axis=1))\n",
    "\t\tP1 = stats.bernoulli.rvs(p1.p, size=k)\n",
    "\t\tP2 = stats.bernoulli.rvs(p2.p, size=k)\n",
    "\n",
    "\t\tt0 = round(stats.uniform.rvs(0, C[0], size=1)[0])\n",
    "\t\tC = iter(C)\n",
    "\n",
    "\n",
    "\t\tfor interruption1, interruption2 in zip(P1, P2):\n",
    "\t\t\tc, f1, f2 = round(next(C)), next(F1), next(F2)\n",
    "\t\t\ts1, s2 = round(c * (1 - f1)), round(c * (1 - f2))\n",
    "\t\t\tl1, l2 = c - s1, c - s2\n",
    "\n",
    "\t\t\tif not interruption1:\n",
    "\t\t\t\tnight1 += [1] * s1 + [0] * l1\n",
    "\t\t\telse:\n",
    "\t\t\t\tu_min, u_max = next(U_mins1), next(U_maxs1)\n",
    "\t\t\t\ts11 = round(s1 * u_min)\n",
    "\t\t\t\tl11 = round(s1 * (u_max - u_min))\n",
    "\t\t\t\ts12 = s1 - s11 - l11\n",
    "\t\t\t\tassert s12 >= 0\n",
    "\n",
    "\t\t\t\tnight1 += [1] * s11 + [0] * l11 + [1] * s12 + [0] * l1\n",
    "\t\t\tif not interruption2:\n",
    "\t\t\t\tnight2 += [1] * s2 + [0] * l2\n",
    "\t\t\telse:\n",
    "\t\t\t\tu_min, u_max = next(U_mins2), next(U_maxs2)\n",
    "\t\t\t\ts21 = round(s2 * u_min)\n",
    "\t\t\t\tl21 = round(s2 * (u_max - u_min))\n",
    "\t\t\t\ts22 = s2 - s21 - l21\n",
    "\t\t\t\tassert s22 >= 0\n",
    "\n",
    "\t\t\t\tnight2 += [1] * s21 + [0] * l21 + [1] * s22 + [0] * l2\n",
    "\tnight1 = night1[t0:]\n",
    "\tnight2 = night2[t0:]\n",
    "\tif delta > 0:\n",
    "\t\tnight1 = night1[delta:]\n",
    "\telif delta < 0:\n",
    "\t\tnight2 = night2[delta:]\n",
    "\tnight1 = night1[:max_length]\n",
    "\tnight2 = night2[:max_length]\n",
    "\n",
    "\tnight1_trimmed, num_removed_phases1 = remove_small_cycles(night1, remove_length)\n",
    "\tnight2_trimmed, num_removed_phases2 = remove_small_cycles(night2, remove_length)\n",
    "\treturn night1, night1_trimmed, night2, night2_trimmed, num_removed_phases1, num_removed_phases2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_E_at_lag(n1, n2, lag):\n",
    "    if lag > 0:\n",
    "        E = np.mean(n1[:-lag] * n2[lag:])\n",
    "    elif lag < 0:\n",
    "        E = np.mean(n1[-lag:] * n2[:lag])\n",
    "    else:\n",
    "        E = np.mean(n1 * n2)\n",
    "    return E\n",
    "\n",
    "def compute_E(p1: Params, p2: Params, n=100, max_lag=100):\n",
    "    n1, _, n2, _, _, _ = generate_shared_night(p1, p2, max_length=n, k=round(np.log(n)))\n",
    "    print(len(n1))\n",
    "    lags = np.arange(-max_lag, max_lag+1)\n",
    "    E = np.array([compute_E_at_lag(np.array(n1), np.array(n2), lag) for lag in lags])\n",
    "    return E\n",
    "\n",
    "def compute_CCF(p1: Params, p2: Params, n=100, max_lag=100):\n",
    "    E = compute_E(p1, p2, n=n, max_lag=max_lag)\n",
    "\n",
    "    mu_X1 = p1.beta / (p1.alpha + p1.beta)\n",
    "    mu_X2 = p2.beta / (p2.alpha + p2.beta)\n",
    "\n",
    "    mu_1 = (1 - p1.p/3) * mu_X1\n",
    "    mu_2 = (1 - p2.p/3) * mu_X2\n",
    "\n",
    "    var_1 = mu_X1 * (1 - p1.p/3) * (1 - mu_X1 * (1 - p1.p/3))\n",
    "    var_2 = mu_X2 * (1 - p2.p/3) * (1 - mu_X2 * (1 - p2.p/3))\n",
    "\n",
    "    CCF = (E - mu_1 * mu_2) / np.sqrt(var_1 * var_2)\n",
    "    return CCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the empirical CCF of two nights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ccf_night(x, y, mode='full', max_lag=None):\n",
    "\t# Calculate raw cross-correlation\n",
    "\tccf = correlate(x - np.mean(x), y - np.mean(y), mode, method='fft')\n",
    "\t\n",
    "\t# Normalize the raw cross-correlation\n",
    "\tccf /= np.sqrt(np.sum((x - np.mean(x))**2) * np.sum((y - np.mean(y))**2))\n",
    "\tif max_lag is not None:\n",
    "\t\tccf = ccf[len(ccf)//2-max_lag:len(ccf)//2+max_lag+1]\n",
    "\treturn ccf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the theoretical CCF of two animals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccf_pair_theo(p1, p2, max_lag=6*60, n=100):\n",
    "\t\"\"\" Compute the theoretical cross-correlation function (CCF) for a pair of parameters. \"\"\"\n",
    "\tn1, _, n2, _, _, _ = generate_shared_night(p1, p2, n)\n",
    "\tccf = compute_ccf_night(n1, n2, max_lag=max_lag)\n",
    "\treturn ccf\n",
    "\n",
    "\n",
    "def tf(u, delta, ccf):\n",
    "\t\"\"\" Shift the cross-correlation function (CCF) by delta and scale it by u. \"\"\"\n",
    "\tk = len(ccf) // 2\n",
    "\tlags = np.arange(-k, k+1)\n",
    "\tshifted_ccf = np.nan_to_num(np.interp(lags + delta, lags, ccf))\n",
    "\treturn u * shifted_ccf\n",
    "\n",
    "\n",
    "def fit_delta_u(emp_ccf, theo_ccf):\n",
    "\t\"\"\" Fit the shift delta and scale u of the theoretical CCF to the empirical CCF. \"\"\"\n",
    "\tk = len(emp_ccf) // 2\n",
    "\tlags = np.arange(-k, k+1)\n",
    "\tassert len(emp_ccf) == len(theo_ccf) == len(lags), f'{len(emp_ccf)} != {len(theo_ccf)} != {len(lags)}'\n",
    "\n",
    "\tdef f(u, delta):\n",
    "\t\tshifted_ccf_theo = np.nan_to_num(np.interp(lags + delta, lags, theo_ccf))\n",
    "\t\ty = np.sum((u * shifted_ccf_theo - emp_ccf)[k-4*60**2:k + 4 * 60**2]**2)\n",
    "\t\treturn y\n",
    "\n",
    "\tcost = np.inf\n",
    "\tfor delta in range(-1200, 1200, 6):\n",
    "\t\tres = least_squares(f, [.5], args=(delta,), bounds=([0], [1]))\n",
    "\t\tif res.cost < cost:\n",
    "\t\t\tcost = res.cost\n",
    "\t\t\tbest_res = res\n",
    "\t\t\tbest_delta = delta\n",
    "\tprint(best_delta, best_res.x)\n",
    "\treturn best_delta, best_res.x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of Parameter Estimation in the IBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funnctions to simulate nights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_night(p1, k=100, max_length=11*60*60, remove_length=300) -> tuple[list[int]]:\n",
    "\tnight = []\n",
    "\twhile len(night) <= (max_length + 10*p1.mu):\n",
    "\t\tC = stats.truncnorm.rvs(-p1.mu/p1.sigma, np.inf, loc=p1.mu, scale=p1.sigma, size=k)\n",
    "\t\tF1 = iter(stats.beta.rvs(p1.alpha, p1.beta, size=k))\n",
    "\t\tU1 = stats.uniform.rvs(size=(k, 2))\n",
    "\t\tU_mins1 = iter(np.min(U1, axis=1))\n",
    "\t\tU_maxs1 = iter(np.max(U1, axis=1))\n",
    "\t\tP1 = stats.bernoulli.rvs(p1.p, size=k)\n",
    "\n",
    "\t\tt0 = round(stats.uniform.rvs(0, C[0], size=1)[0])\n",
    "\t\tC = iter(C)\n",
    "\n",
    "\t\tfor interruption1 in P1:\n",
    "\t\t\tc, f1 = round(next(C)), next(F1)\n",
    "\t\t\ts1 = round(c * (1 - f1))\n",
    "\t\t\tl1 = c - s1\n",
    "\n",
    "\t\t\tif not interruption1:\n",
    "\t\t\t\tnight += [1] * s1 + [0] * l1\n",
    "\t\t\telse:\n",
    "\t\t\t\tu_min, u_max = next(U_mins1), next(U_maxs1)\n",
    "\t\t\t\ts11 = round(s1 * u_min)\n",
    "\t\t\t\tl11 = round(s1 * (u_max - u_min))\n",
    "\t\t\t\ts12 = s1 - s11 - l11\n",
    "\t\t\t\tassert s12 >= 0\n",
    "\n",
    "\t\t\t\tnight += [1] * s11 + [0] * l11 + [1] * s12 + [0] * l1\n",
    "\t\t\t\n",
    "\tnight = night[t0:]\n",
    "\tnight = night[:max_length]\n",
    "\n",
    "\tnight_trimmed, num_removed_phases = remove_small_cycles(night, remove_length)\n",
    "\treturn night, night_trimmed, num_removed_phases\n",
    "\n",
    "\n",
    "def trim_partial_cycles(n):\n",
    "\tif n[0]:\n",
    "\t\tn = 1 - np.trim_zeros(1-n, 'f')\n",
    "\tn = np.trim_zeros(n, 'fb')\n",
    "\tn = 1 - np.trim_zeros(1-n, 'b')\n",
    "\treturn n\n",
    "\n",
    "\n",
    "def get_scs_lfs(n):\n",
    "\tn = trim_partial_cycles(n)\n",
    "\tif n.size == 0:\n",
    "\t\treturn [], []\n",
    "\tone_seq = np.split(n, np.where(np.diff(n) != 0)[0] + 1)\n",
    "\tif len(one_seq) == 0:\n",
    "\t\treturn [], []\n",
    "\tone_seq = np.array([len(seq) for seq in one_seq if seq[0] == 1])\n",
    "\tzero_seq = np.split(n, np.where(np.diff(n) != 0)[0] + 1)\n",
    "\tif len(zero_seq) == 0:\n",
    "\t\treturn [], []\n",
    "\tzero_seq = np.array([len(seq) for seq in zero_seq if seq[0] == 0])\n",
    "\n",
    "\tscs = one_seq + zero_seq\n",
    "\tlfs = zero_seq / scs\n",
    "\n",
    "\treturn scs, lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run Simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_IBN(BINS, RUNS, NIGHTS, P):\t\n",
    "\tp = Params(144*60, 40*60, 5.25, 2.52, P)\n",
    "\n",
    "\tnights = np.zeros((RUNS, NIGHTS, 11*60*60), dtype=np.uint8)\n",
    "\tnights_trimmed = np.zeros((RUNS, NIGHTS, 11*60*60), dtype=np.uint8)\n",
    "\tnum_removed_phases = np.zeros((RUNS, NIGHTS), dtype=np.uint16)\n",
    "\n",
    "\tfor i in trange(RUNS):\n",
    "\t\tfor j in range(NIGHTS):\n",
    "\t\t\tnights[i][j], nights_trimmed[i][j], num_removed_phases[i][j] = generate_night(p)\n",
    "\n",
    "\tscs, lfs = [], []\n",
    "\tscs_trimmed, lfs_trimmed = [], []\n",
    "\tfor i in trange(RUNS):\n",
    "\t\tscs_, lfs_, = [], []\n",
    "\t\tscs_trimmed_, lfs_trimmed_ = [], []\n",
    "\n",
    "\t\tfor j in range(NIGHTS):\n",
    "\t\t\tscs__, lfs__ = get_scs_lfs(nights[i][j])\n",
    "\t\t\tscs_.extend([s/60 for s in scs__])\n",
    "\t\t\tlfs_.extend(lfs__)\n",
    "\t\tscs.append(scs_)\n",
    "\t\tlfs.append(lfs_)\n",
    "\n",
    "\t\tfor j in range(NIGHTS):\n",
    "\t\t\tscs__, lfs__ = get_scs_lfs(nights_trimmed[i][j])\n",
    "\t\t\tscs_trimmed_.extend([s/60 for s in scs__])\n",
    "\t\t\tlfs_trimmed_.extend(lfs__)\n",
    "\t\tscs_trimmed.append(scs_trimmed_)\n",
    "\t\tlfs_trimmed.append(lfs_trimmed_)\n",
    "\t\n",
    "\n",
    "\tfor i in trange(RUNS, desc='Fitting'):\n",
    "\t\tresults = fit_IBN(scs[i], lfs[i], BINS)\n",
    "\t\twith open(f'IBN_fitting_simulation_results_{RUNS}runs_{BINS}bins_{NIGHTS}nights.csv', 'a') as f:\n",
    "\t\t\tf.write(f'{i},{RUNS},{BINS},{NIGHTS},{\",\".join(map(str, p))},{\",\".join(map(str, results))},0,False,{len(scs[i])}\\n')\n",
    "\t\tresults = fit_IBN(scs_trimmed[i], lfs_trimmed[i], BINS)\n",
    "\t\twith open(f'IBN_fitting_simulation_results_{RUNS}runs_{BINS}bins_{NIGHTS}nights.csv', 'a') as f:\n",
    "\t\t\tf.write(f'{i},{RUNS},{BINS},{NIGHTS},{\",\".join(map(str, p))},{\",\".join(map(str, results))},{str(np.sum(num_removed_phases[i]))},True,{len(scs_trimmed[i])}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [10, 20, 30, 40, 50, 60]\n",
    "nights = [10, 20, 30, 40, 50, 80, 90, 100]\n",
    "pis = [0, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "for b, n, p in itertools.product(bins, nights, pis):\n",
    "    run_simulation_IBN(b, 100, n, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of paramter estimation in the S-IBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ccf(x, y, maxlags=None):\n",
    "\t\"\"\"Compute the cross-correlation function.\"\"\"\n",
    "\tif maxlags is None:\n",
    "\t\tmaxlags = len(x) - 1\n",
    "\tcorrelation = correlate(x - np.mean(x), y - np.mean(y), mode='full', method='fft')\n",
    "\tlags = correlation_lags(len(x), len(y), mode='full')\n",
    "\tcorrelation = correlation / (len(x) * np.std(x) * np.std(y))\n",
    "\tmidpoint = len(correlation) // 2\n",
    "\treturn correlation[midpoint-maxlags:midpoint+maxlags+1], lags[midpoint-maxlags:midpoint+maxlags+1]\n",
    "\n",
    "def run_simulation_SIBN(BINS, RUNS, NIGHTS, P1, P2, DELTA, U, REMOVE, MAXLAGS=18000):\n",
    "\tp1 = Params(144*60, 40*60, 5.25, 2.52, P1)\n",
    "\tp2 = Params(144*60, 40*60, 5.25, 2.52, P2)\n",
    "\n",
    "\tnights1, nights2 = np.zeros((RUNS, NIGHTS, 11*60*60), dtype=np.uint8), np.zeros((RUNS, NIGHTS, 11*60*60), dtype=np.uint8)\n",
    "\tnights1_trimmed, nights2_trimmed = np.zeros((RUNS, NIGHTS, 11*60*60), dtype=np.uint8), np.zeros((RUNS, NIGHTS, 11*60*60), dtype=np.uint8)\n",
    "\tnum_removed_phases1, num_removed_phases2 = np.zeros((RUNS, NIGHTS), dtype=np.uint16), np.zeros((RUNS, NIGHTS), dtype=np.uint16)\n",
    "\n",
    "\tfor i in trange(RUNS):\n",
    "\t\tfor j in range(int(U * NIGHTS)):\n",
    "\t\t\tnights1[i][j], nights1_trimmed[i][j], nights2[i][j], nights2_trimmed[i][j], num_removed_phases1[i][j], num_removed_phases2[i][j] = generate_shared_night(p1, p2, delta=DELTA, remove_length=REMOVE)\n",
    "\t\tfor j in range(int(U * NIGHTS), NIGHTS):\n",
    "\t\t\tnights1[i][j], nights1_trimmed[i][j], num_removed_phases1[i][j] = generate_night(p1, remove_length=REMOVE)\n",
    "\t\t\tnights2[i][j], nights2_trimmed[i][j], num_removed_phases2[i][j] = generate_night(p2, remove_length=REMOVE)\n",
    "\tscs1, lfs1, scs2, lfs2 = [], [], [], []\n",
    "\tscs1_trimmed, lfs1_trimmed, scs2_trimmed, lfs2_trimmed = [], [], [], []\n",
    "\n",
    "\tnp.save(f'CCF_SIBN_trimmed_untrimmed_fit_simulation_results_nights1_{RUNS}runs_{NIGHTS}nights_{BINS}bins_{U}u_{DELTA}delta.npy', nights1)\n",
    "\tnp.save(f'CCF_SIBN_trimmed_untrimmed_fit_simulation_results_nights2_{RUNS}runs_{NIGHTS}nights_{BINS}bins_{U}u_{DELTA}delta.npy', nights2)\n",
    "\tnp.save(f'CCF_SIBN_trimmed_untrimmed_fit_simulation_results_nights1_trimmed_{RUNS}runs_{NIGHTS}nights_{BINS}bins_{U}u_{DELTA}delta.npy', nights1_trimmed)\n",
    "\tnp.save(f'CCF_SIBN_trimmed_untrimmed_fit_simulation_results_nights2_trimmed_{RUNS}runs_{NIGHTS}nights_{BINS}bins_{U}u_{DELTA}delta.npy', nights2_trimmed)\n",
    "\n",
    "\tfor i in trange(RUNS):\n",
    "\t\tscs1_, lfs1_, scs2_, lfs2_ = [], [], [], []\n",
    "\t\tfor j in range(NIGHTS):\n",
    "\t\t\tscs, lfs = get_scs_lfs(nights1[i][j])\n",
    "\t\t\tscs1_.extend([s/60 for s in scs])\n",
    "\t\t\tlfs1_.extend(lfs)\n",
    "\t\t\tscs, lfs = get_scs_lfs(nights2[i][j])\n",
    "\t\t\tscs2_.extend([s/60 for s in scs])\n",
    "\t\t\tlfs2_.extend(lfs)\n",
    "\t\tscs1.append(scs1_)\n",
    "\t\tlfs1.append(lfs1_)\n",
    "\t\tscs2.append(scs2_)\n",
    "\t\tlfs2.append(lfs2_)\n",
    "\n",
    "\t\tscs1_, lfs1_, scs2_, lfs2_ = [], [], [], []\n",
    "\t\tfor j in range(NIGHTS):\n",
    "\t\t\tscs, lfs = get_scs_lfs(nights1_trimmed[i][j])\n",
    "\t\t\tscs1_.extend([s/60 for s in scs])\n",
    "\t\t\tlfs1_.extend(lfs)\n",
    "\t\t\tscs, lfs = get_scs_lfs(nights2_trimmed[i][j])\n",
    "\t\t\tscs2_.extend([s/60 for s in scs])\n",
    "\t\t\tlfs2_.extend(lfs)\n",
    "\t\tscs1_trimmed.append(scs1_)\n",
    "\t\tlfs1_trimmed.append(lfs1_)\n",
    "\t\tscs2_trimmed.append(scs2_)\n",
    "\t\tlfs2_trimmed.append(lfs2_)\n",
    "\n",
    "\ttheoretical_ccfs_untrimmed = np.zeros(RUNS, 2 * MAXLAGS + 1)\n",
    "\ttheoretical_ccfs_trimmed = np.zeros(RUNS, 2 * MAXLAGS + 1)\n",
    "\tavg_ccfs_untrimmed = np.zeros((RUNS, 2*MAXLAGS+1))\n",
    "\tavg_ccfs_trimmed = np.zeros((RUNS, 2*MAXLAGS+1))\n",
    "\tlags = np.zeros(2*MAXLAGS+1)\n",
    "\n",
    "\n",
    "\n",
    "\tfor i in trange(RUNS, desc='Fitting'):\n",
    "\t\tresults = fit_SIBN(scs1[i], lfs1[i], scs2[i], lfs2[i], BINS)\n",
    "\t\tresults_trimmed = fit_SIBN(scs1_trimmed[i], lfs1_trimmed[i], scs2_trimmed[i], lfs2_trimmed[i], BINS)\n",
    "\n",
    "\t\t# Compute theoretical CCF:\n",
    "\t\tp1 = Params(*results[:5])\n",
    "\t\tp2 = Params(*results[:2], *results[5:8])\n",
    "\t\t\n",
    "\t\tccf = compute_CCF(p1, p2, max_lag=MAXLAGS)\n",
    "\t\ttheoretical_ccfs_untrimmed[i] = ccf\n",
    "\n",
    "\t\tp1 = Params(*results_trimmed[:5])\n",
    "\t\tp2 = Params(*results_trimmed[:2], *results_trimmed[5:8])\n",
    "\t\t\n",
    "\t\tccf = compute_CCF(p1, p2, max_lag=MAXLAGS)\n",
    "\t\ttheoretical_ccfs_trimmed[i] = ccf\n",
    "\n",
    "\t\t# Compute empirical CCF:\n",
    "\t\tccfs_untrimmed_run = np.zeros((NIGHTS, 2*MAXLAGS+1))\n",
    "\t\tccfs_trimmed_run = np.zeros((NIGHTS, 2*MAXLAGS+1))\n",
    "\n",
    "\t\tfor night in range(NIGHTS):\n",
    "\t\t\t# Untrimmed nights\n",
    "\t\t\tccf, _ = compute_ccf(nights1[i, night], nights2[i, night], maxlags=MAXLAGS)\n",
    "\t\t\tccfs_untrimmed_run[night] = ccf\n",
    "\n",
    "\t\t\t# Trimmed nights\n",
    "\t\t\tccf, _ = compute_ccf(nights1_trimmed[i, night], nights2_trimmed[i, night], maxlags=MAXLAGS)\n",
    "\t\t\tccfs_trimmed_run[night] = ccf\n",
    "\n",
    "\t\t# Average CCFs over nights for this run\n",
    "\t\tavg_ccfs_untrimmed[i] = np.mean(ccfs_untrimmed_run, axis=0)\n",
    "\t\tavg_ccfs_trimmed[i] = np.mean(ccfs_trimmed_run, axis=0)\n",
    "\n",
    "\t\t# Compute delta and u\n",
    "\t\tdelta_untrimmed, u_untrimmed = fit_delta_u(avg_ccfs_untrimmed[i], theoretical_ccfs_untrimmed[i])\n",
    "\t\tdelta_trimmed, u_trimmed = fit_delta_u(avg_ccfs_trimmed[i], theoretical_ccfs_trimmed[i])\n",
    "\n",
    "\n",
    "\t\twith open(f'CCF_SIBN_trimmed_untrimmed_fit_simulation_results_{RUNS}runs_{BINS}bins_{NIGHTS}nights_{DELTA}delta_{U}u.csv', 'a') as f:\n",
    "\t\t\tf.write(f'{i},{RUNS},{BINS},{NIGHTS},{\",\".join(map(str, P1))},{\",\".join(map(str, P2))},{DELTA},{U},{\",\".join(map(str, results))},0,False,{len(scs1[i])},{len(scs2[i])},{delta_untrimmed},{u_untrimmed}\\n')\n",
    "\t\twith open(f'CCF_SIBN_trimmed_untrimmed_fit_simulation_results_{RUNS}runs_{BINS}bins_{NIGHTS}nights_{DELTA}delta_{U}u.csv', 'a') as f:\n",
    "\t\t\tf.write(f'{i},{RUNS},{BINS},{NIGHTS},{\",\".join(map(str, P1))},{\",\".join(map(str, P2))},{DELTA},{U},{\",\".join(map(str, results))},{str(np.sum(num_removed_phases1[i]))},{str(np.sum(num_removed_phases1[i]))},True,{len(scs1_trimmed[i])},{len(scs2_trimmed[i])},{delta_trimmed},{u_trimmed}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nights = [10, 30, 50, 70, 90]\n",
    "deltas = [0, 60, 300]\n",
    "us = [0, 0.5, 0.75, 1]\n",
    "\n",
    "for n, d, u in itertools.product(nights, deltas, us):\n",
    "    run_simulation_SIBN(40, 100, n, 0, 0, d, u, 300)\n",
    "    run_simulation_SIBN(40, 100, n, 0, 0.5, d, u, 300)\n",
    "    run_simulation_SIBN(40, 100, n, 0, 0.9, d, u, 300)\n",
    "    run_simulation_SIBN(40, 100, n, 0.3, 0.9, d, u, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "nights = pd.read_csv('nights.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter animals that have less than 30 fully observed SCs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>species</th>\n",
       "      <th>id</th>\n",
       "      <th>scs</th>\n",
       "      <th>lfs</th>\n",
       "      <th>starts</th>\n",
       "      <th>ends</th>\n",
       "      <th>ly_starts</th>\n",
       "      <th>scs_mean</th>\n",
       "      <th>scs_std</th>\n",
       "      <th>...</th>\n",
       "      <th>mu</th>\n",
       "      <th>sigma</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>pi</th>\n",
       "      <th>nr_scs</th>\n",
       "      <th>nr_nights</th>\n",
       "      <th>partner</th>\n",
       "      <th>nr_scs_per_night</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>male</td>\n",
       "      <td>Oryx dammah</td>\n",
       "      <td>96</td>\n",
       "      <td>[147.58333333333334, 144.78333333333333, 183.4...</td>\n",
       "      <td>[0.6948616600790514, 0.8162771958098308, 0.951...</td>\n",
       "      <td>[125.41666666666667, 376.25, 109.0833333333333...</td>\n",
       "      <td>[273.0, 521.0333333333333, 292.48333333333335,...</td>\n",
       "      <td>[170.45, 402.85, 117.95, 330.6333333333333, 16...</td>\n",
       "      <td>136.277778</td>\n",
       "      <td>56.345254</td>\n",
       "      <td>...</td>\n",
       "      <td>126.595866</td>\n",
       "      <td>51.895132</td>\n",
       "      <td>15.295126</td>\n",
       "      <td>1.675219</td>\n",
       "      <td>1.050116e-01</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>-1</td>\n",
       "      <td>[1, 1, 2, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, ...</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>female</td>\n",
       "      <td>Equus quagga</td>\n",
       "      <td>171</td>\n",
       "      <td>[131.48333333333332, 191.21666666666667, 175.1...</td>\n",
       "      <td>[0.5865128660159716, 0.7132397803538744, 0.732...</td>\n",
       "      <td>[150.15, 281.6333333333333, 472.85, 144.433333...</td>\n",
       "      <td>[281.6333333333333, 472.85, 647.9666666666667,...</td>\n",
       "      <td>[204.51666666666668, 336.46666666666664, 519.7...</td>\n",
       "      <td>176.489744</td>\n",
       "      <td>45.354351</td>\n",
       "      <td>...</td>\n",
       "      <td>191.428873</td>\n",
       "      <td>48.581164</td>\n",
       "      <td>7.780506</td>\n",
       "      <td>3.964330</td>\n",
       "      <td>1.202961e-09</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>[3, 3, 3, 2, 4, 3, 2, 2, 4]</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>female</td>\n",
       "      <td>Equus quagga</td>\n",
       "      <td>175</td>\n",
       "      <td>[335.06666666666666, 97.88333333333334, 419.76...</td>\n",
       "      <td>[0.018802228412256268, 0.11323003575685339, 0....</td>\n",
       "      <td>[127.75, 131.01666666666668, 228.9, 120.75, 12...</td>\n",
       "      <td>[462.81666666666666, 228.9, 648.6666666666666,...</td>\n",
       "      <td>[456.51666666666665, 217.81666666666666, 643.4...</td>\n",
       "      <td>202.154167</td>\n",
       "      <td>123.103883</td>\n",
       "      <td>...</td>\n",
       "      <td>174.920073</td>\n",
       "      <td>3.565168</td>\n",
       "      <td>13.979368</td>\n",
       "      <td>833.182869</td>\n",
       "      <td>5.435323e-01</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex       species   id  \\\n",
       "95     male   Oryx dammah   96   \n",
       "170  female  Equus quagga  171   \n",
       "174  female  Equus quagga  175   \n",
       "\n",
       "                                                   scs  \\\n",
       "95   [147.58333333333334, 144.78333333333333, 183.4...   \n",
       "170  [131.48333333333332, 191.21666666666667, 175.1...   \n",
       "174  [335.06666666666666, 97.88333333333334, 419.76...   \n",
       "\n",
       "                                                   lfs  \\\n",
       "95   [0.6948616600790514, 0.8162771958098308, 0.951...   \n",
       "170  [0.5865128660159716, 0.7132397803538744, 0.732...   \n",
       "174  [0.018802228412256268, 0.11323003575685339, 0....   \n",
       "\n",
       "                                                starts  \\\n",
       "95   [125.41666666666667, 376.25, 109.0833333333333...   \n",
       "170  [150.15, 281.6333333333333, 472.85, 144.433333...   \n",
       "174  [127.75, 131.01666666666668, 228.9, 120.75, 12...   \n",
       "\n",
       "                                                  ends  \\\n",
       "95   [273.0, 521.0333333333333, 292.48333333333335,...   \n",
       "170  [281.6333333333333, 472.85, 647.9666666666667,...   \n",
       "174  [462.81666666666666, 228.9, 648.6666666666666,...   \n",
       "\n",
       "                                             ly_starts    scs_mean  \\\n",
       "95   [170.45, 402.85, 117.95, 330.6333333333333, 16...  136.277778   \n",
       "170  [204.51666666666668, 336.46666666666664, 519.7...  176.489744   \n",
       "174  [456.51666666666665, 217.81666666666666, 643.4...  202.154167   \n",
       "\n",
       "        scs_std  ...          mu      sigma      alpha        beta  \\\n",
       "95    56.345254  ...  126.595866  51.895132  15.295126    1.675219   \n",
       "170   45.354351  ...  191.428873  48.581164   7.780506    3.964330   \n",
       "174  123.103883  ...  174.920073   3.565168  13.979368  833.182869   \n",
       "\n",
       "               pi  nr_scs  nr_nights  partner  \\\n",
       "95   1.050116e-01      21         23       -1   \n",
       "170  1.202961e-09      26          9       -1   \n",
       "174  5.435323e-01       8         27       -1   \n",
       "\n",
       "                                      nr_scs_per_night    age  \n",
       "95   [1, 1, 2, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, ...  adult  \n",
       "170                        [3, 3, 3, 2, 4, 3, 2, 2, 4]  adult  \n",
       "174  [0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 1, 0, 1, ...  adult  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query('nr_scs < 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('nr_scs >= 30')\n",
    "nights = nights[nights['id'].isin(data['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    129\n",
       "male       60\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Equus quagga                32\n",
       "Tragelaphus oryx            25\n",
       "Kobus ellipsiprymnus        19\n",
       "Connochaetes taurinus       17\n",
       "Damaliscus pygargus         14\n",
       "Okapia johnstoni            11\n",
       "Tragelaphus eurycerus       10\n",
       "Equus grevyi                10\n",
       "Addax nasomaculatus          8\n",
       "Syncerus c. nanus            7\n",
       "Equus zebra                  7\n",
       "Tragelaphus strepsiceros     6\n",
       "Hippotragus equinus          6\n",
       "Oryx dammah                  5\n",
       "Syncerus c. caffer           5\n",
       "Hippotragus niger            4\n",
       "Oryx leucoryx                3\n",
       "Redunca fulvorufula          2\n",
       "Tragelaphus spekii           1\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.species.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult       153\n",
       "subadult     20\n",
       "young        16\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation of the model assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unimodal    150\n",
       "bimodal      39\n",
       "Name: modal, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.modal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serial dependence of SC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05746445494229766, 0.009950937292967888)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def serial_correlation(row):\n",
    "    scs = str2float(row['scs'])\n",
    "    if len(scs) < 3:\n",
    "        return np.nan\n",
    "    corr = np.corrcoef(scs[:-1], scs[1:])[0, 1]\n",
    "    return corr\n",
    "\n",
    "data['scs_serial_corr'] = data.apply(serial_correlation, axis=1)\n",
    "\n",
    "data['scs_serial_corr'].mean(), data['scs_serial_corr'].sem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase or decrease of SC during night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrr(row):\n",
    "    if len(row['scs']) < 3:\n",
    "        return np.nan\n",
    "    scs = str2float(row['scs'])\n",
    "    xcs = str2float(row['starts'])\n",
    "    if len(scs) < 3:\n",
    "        return np.nan\n",
    "    return np.polyfit(xcs, scs, 1)[0]\n",
    "\n",
    "nights['scs_reg'] = nights.apply(regrr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.344833112687312, 11.84788625254998)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nights['scs_reg'].mean() * 60, nights['scs_reg'].sem() * 60 * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serial dependence of LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.049652033809106884, 0.011504099776625698)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def serial_correlation(row):\n",
    "    scs = str2float(row['lfs'])\n",
    "    if len(scs) < 3:\n",
    "        return np.nan\n",
    "    corr = np.corrcoef(scs[:-1], scs[1:])[0, 1]\n",
    "    return corr\n",
    "\n",
    "data['lfs_serial_corr'] = data.apply(serial_correlation, axis=1)\n",
    "\n",
    "data['lfs_serial_corr'].mean(), data['lfs_serial_corr'].sem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase or decrease of LF during night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0100388935718708, 0.02983527449348149)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regrr(row):\n",
    "    if len(row['lfs']) < 3:\n",
    "        return np.nan\n",
    "    scs = str2float(row['lfs'])\n",
    "    xcs = str2float(row['starts'])\n",
    "    if len(scs) < 3:\n",
    "        return np.nan\n",
    "    return np.polyfit(xcs, scs, 1)[0]\n",
    "\n",
    "nights['lfs_reg'] = nights.apply(regrr, axis=1)\n",
    "\n",
    "nights['lfs_reg'].mean() * 60, nights['lfs_reg'].sem() * 60 * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No significant difference in IBN based regularity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scs_m(row):\n",
    "    scs = str2float(row['scs'])\n",
    "    if len(scs) < 3:\n",
    "        return np.nan\n",
    "    return np.mean(scs)\n",
    "\n",
    "def scs_sd(row):\n",
    "    scs = str2float(row['scs'])\n",
    "    if len(scs) < 3:\n",
    "        return np.nan\n",
    "    return np.std(scs)\n",
    "\n",
    "data['m'] = data.apply(scs_m, axis=1)\n",
    "data['s'] = data.apply(scs_sd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cv'] = data.s / data.m\n",
    "data['ibn_cv'] = data.sigma / data.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data.query('ibn_cv < 1.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3253.0, pvalue=8.055474215139646e-14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.wilcoxon(data_['cv'], data_['ibn_cv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV:\n",
      "adult vs. young: MannwhitneyuResult(statistic=456.0, pvalue=0.00013041889327624647)\n",
      "adult vs. subadult: MannwhitneyuResult(statistic=1676.0, pvalue=0.45761387979779977)\n",
      "subadult vs. young: MannwhitneyuResult(statistic=62.0, pvalue=0.003537936478222105)\n"
     ]
    }
   ],
   "source": [
    "print('CV:')\n",
    "print('adult vs. young:', stats.mannwhitneyu(data_.query('age == \"adult\"')['cv'], data_.query('age == \"young\"')['cv']))\n",
    "print('adult vs. subadult:', stats.mannwhitneyu(data_.query('age == \"adult\"')['cv'], data_.query('age == \"subadult\"')['cv']))\n",
    "print('subadult vs. young:', stats.mannwhitneyu(data_.query('age == \"subadult\"')['cv'], data_.query('age == \"young\"')['cv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBN-CV:\n",
      "adult vs. young: MannwhitneyuResult(statistic=856.0, pvalue=0.11255842060948171)\n",
      "adult vs. subadult: MannwhitneyuResult(statistic=1895.0, pvalue=0.07363321908685885)\n",
      "subadult vs. young: MannwhitneyuResult(statistic=94.0, pvalue=0.06431354959122743)\n"
     ]
    }
   ],
   "source": [
    "print('IBN-CV:')\n",
    "print('adult vs. young:', stats.mannwhitneyu(data_.query('age == \"adult\"')['ibn_cv'], data_.query('age == \"young\"')['ibn_cv']))\n",
    "print('adult vs. subadult:', stats.mannwhitneyu(data_.query('age == \"adult\"')['ibn_cv'], data_.query('age == \"subadult\"')['ibn_cv']))\n",
    "print('subadult vs. young:', stats.mannwhitneyu(data_.query('age == \"subadult\"')['ibn_cv'], data_.query('age == \"young\"')['ibn_cv']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher interruption probabilities in younger animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi:\n",
      "adult vs. young: MannwhitneyuResult(statistic=551.0, pvalue=0.0009879459340609922)\n",
      "adult vs. subadult: MannwhitneyuResult(statistic=1323.0, pvalue=0.34792167732735235)\n",
      "subadult vs. young: MannwhitneyuResult(statistic=99.0, pvalue=0.09231058101189886)\n"
     ]
    }
   ],
   "source": [
    "print('Pi:')\n",
    "print('adult vs. young:', stats.mannwhitneyu(data_.query('age == \"adult\"')['pi'], data_.query('age == \"young\"')['pi']))\n",
    "print('adult vs. subadult:', stats.mannwhitneyu(data_.query('age == \"adult\"')['pi'], data_.query('age == \"subadult\"')['pi']))\n",
    "print('subadult vs. young:', stats.mannwhitneyu(data_.query('age == \"subadult\"')['pi'], data_.query('age == \"young\"')['pi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     14\n",
       "False     2\n",
       "Name: pi, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.query('age == \"young\"').pi > 0.05).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     15\n",
       "False     5\n",
       "Name: pi, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.query('age == \"subadult\"').pi > 0.05).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     84\n",
       "False    69\n",
       "Name: pi, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.query('age == \"adult\"').pi > 0.05).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chi2ContingencyResult(statistic=8.555073426669225, pvalue=0.01387680256303785, dof=2, expected_freq=array([[ 9.56613757, 11.95767196, 91.47619048],\n",
       "       [ 6.43386243,  8.04232804, 61.52380952]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency([[14, 15, 84], [2, 5, 69]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     37\n",
       "False     2\n",
       "Name: pi, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.query('modal == \"bimodal\"').pi > 0.05).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     76\n",
       "False    74\n",
       "Name: pi, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.query('modal == \"unimodal\"').pi > 0.05).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
